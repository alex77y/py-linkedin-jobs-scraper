{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "from linkedin_jobs_scraper import LinkedinScraper\n",
    "from linkedin_jobs_scraper.events import Events, EventData, EventMetrics\n",
    "from linkedin_jobs_scraper.query import Query, QueryOptions, QueryFilters\n",
    "from linkedin_jobs_scraper.filters import RelevanceFilters, TimeFilters, TypeFilters, ExperienceLevelFilters, \\\n",
    "    OnSiteOrRemoteFilters, SalaryBaseFilters\n",
    "import pandas as pd\n",
    "from linkedin_jobs_scraper.utils.chrome_driver import build_driver\n",
    "import time\n",
    "from datetime import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FieldName = ['job_id', 'title', 'company','date','link','insight','description']\n",
    "today = datetime.now().strftime(\"%y_%m_%d\")\n",
    "target_csv = f\"job_scan_{today}.csv\"\n",
    "\n",
    "# Create the output csv if not exist\n",
    "if target_csv and not os.path.exists(target_csv):\n",
    "    with open(target_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file,fieldnames=FieldName)\n",
    "        writer.writeheader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:li:scraper:('Using strategy AuthenticatedStrategy',)\n"
     ]
    }
   ],
   "source": [
    "# Function to append each result to the CSV file\n",
    "def write_output(result, csv_file,FieldName = FieldName):\n",
    "    with open(csv_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=FieldName)\n",
    "        writer.writerow(result)\n",
    "\n",
    "\n",
    "# Change root logger level (default is WARN)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "# Fired once for each successfully processed job\n",
    "def on_data(data: EventData):\n",
    "    print(target_csv)\n",
    "    print('[ON_DATA]',data.job_id, data.title, data.company, data.date, data.link, data.insights,\n",
    "          len(data.description))\n",
    "    output = {'job_id':data.job_id, 'title':data.title, 'company':data.company,'date':data.date,'link':data.link,'insight':data.insights,'description':data.description}\n",
    "    write_output(output, target_csv)\n",
    "\n",
    "# Fired once for each page (25 jobs)\n",
    "def on_metrics(metrics: EventMetrics):\n",
    "    print('[ON_METRICS]', str(metrics))\n",
    "\n",
    "\n",
    "def on_error(error):\n",
    "    print('[ON_ERROR]', error)\n",
    "\n",
    "\n",
    "def on_end():\n",
    "    print('[ON_END]')\n",
    "\n",
    "\n",
    "scraper = LinkedinScraper(\n",
    "    chrome_executable_path=None,  # Custom Chrome executable path (e.g. /foo/bar/bin/chromedriver)\n",
    "    chrome_binary_location=None,  \n",
    "    chrome_options=None,  # Custom Chrome options here\n",
    "    headless=True,  # Overrides headless mode only if chrome_options is None\n",
    "    max_workers=1,  # How many threads will be spawned to run queries concurrently (one Chrome driver for each thread)\n",
    "    slow_mo=0.5,  # Slow down the scraper to avoid 'Too many requests 429' errors (in seconds)\n",
    "    page_load_timeout=40,\n",
    "  # Page load timeout (in seconds)    \n",
    ")\n",
    "\n",
    "# Add event listeners\n",
    "scraper.on(Events.DATA, on_data)\n",
    "scraper.on(Events.ERROR, on_error)\n",
    "scraper.on(Events.END, on_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:li:scraper:('Starting new query', \"Query(query= options=QueryOptions(limit=1000 locations=['United States'] filters=QueryFilters(company_jobs_url=https://www.linkedin.com/jobs/search/?f_C=95311953&geoId=92000000&origin=COMPANY_PAGE_JOBS_CLUSTER_EXPANSION&originToLandingJobPostings=3966683952) apply_link=False skip_promoted_jobs=True page_offset=0))\")\n",
      "INFO:li:scraper:('Chrome debugger url', 'http://localhost:51647')\n",
      "INFO:li:scraper:('Websocket debugger url: ', 'ws://localhost:51647/devtools/page/EBCBF3AEF496FBE5BEE9A188BBED873B')\n",
      "INFO:li:scraper:('[][United States]', 'Setting authentication cookie')\n",
      "INFO:li:scraper:('[][United States]', 'Opening https://www.linkedin.com/jobs/search?location=United+States&f_C=95311953&start=0')\n",
      "INFO:li:scraper:('[][United States]', 'Session is valid')\n",
      "INFO:li:scraper:('[][United States][1]', 'Processed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_scan_24_07_18.csv\n",
      "[ON_DATA] 3966683952 Senior Research Associate, RNA Sciences (Application Sciences) Addition Therapeutics  https://www.linkedin.com/jobs/view/3966683952/?eBP=NON_CHARGEABLE_CHANNEL&refId=BshJlRjmvkK6wqc7gSabTg%3D%3D&trackingId=R11U3U6B16BteFZt42QXJw%3D%3D&trk=flagship3_search_srp_jobs ['$95K/yr - $110K/yr On-site Full-time Entry level', 'Research', '11-50 employees · Biotechnology Research', 'Skills: RNA, Molecular Biology, +8 more', 'See how you compare to over 100 other applicants. Try Premium for $0'] 3780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:li:scraper:('[][United States][2]', 'Processed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_scan_24_07_18.csv\n",
      "[ON_DATA] 3978695218 Associate Scientist/Scientist, RNA Process Development Addition Therapeutics  https://www.linkedin.com/jobs/view/3978695218/?eBP=NON_CHARGEABLE_CHANNEL&refId=BshJlRjmvkK6wqc7gSabTg%3D%3D&trackingId=OkxNKvHy0JYs%2BvsUP%2F2PSQ%3D%3D&trk=flagship3_search_srp_jobs ['$115K/yr - $135K/yr On-site Full-time Mid-Senior level', '11-50 employees · Biotechnology Research', 'Skills: Purification, Molecular Biology, +8 more', 'See how you compare to over 100 other applicants. Try Premium for $0', '', 'Am I a good fit for this job?', 'How can I best position myself for this job?', 'Tell me more about Addition ...'] 3310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:li:scraper:('[][United States][3]', 'Skipped because promoted')\n",
      "INFO:li:scraper:('[][United States][4]', 'Skipped because promoted')\n",
      "INFO:li:scraper:('[][United States][5]', 'Skipped because promoted')\n",
      "INFO:li:scraper:('[][United States]', 'No more jobs to process in this page')\n",
      "INFO:li:scraper:('[][United States]', 'Metrics:', '{ processed: 2, failed: 0, missed: 20, skipped: 3 }')\n",
      "INFO:li:scraper:('[][United States]', 'Pagination requested [1]')\n",
      "INFO:li:scraper:('[][United States]', 'Opening https://www.linkedin.com/jobs/search?location=United+States&f_C=95311953&start=25')\n",
      "INFO:li:scraper:('[][United States]', 'Waiting for new jobs to load')\n",
      "INFO:li:scraper:('[][United States]', \"Couldn't find more jobs for the running query\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ON_END]\n"
     ]
    }
   ],
   "source": [
    "linked_page = pd.read_csv('linkedin_pages.csv')\n",
    "execute_list = linked_page.dropna()\n",
    "sample = execute_list.iloc[10,:]\n",
    "for link in execute_list['job_link']:\n",
    "    query = Query(    \n",
    "        options=QueryOptions(\n",
    "            locations=['United States'],\n",
    "            skip_promoted_jobs=True,\n",
    "            limit = 1000,      \n",
    "            filters=QueryFilters(\n",
    "                company_jobs_url= link\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    scraper.run(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
